[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[project]
name = "openvla-oft"
authors = [
    {name = "Moo Jin Kim", email="moojink@stanford.edu"},
    {name = "Chelsea Finn", email="cbfinn@cs.stanford.edu"},
    {name = "Percy Liang", email="pliang@cs.stanford.edu"},
]
description = "Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success"
version = "0.0.1"
readme = "README.md"
requires-python = ">=3.8"
keywords = ["vision-language-actions models", "fine-tuning", "robot learning"]
license = {file = "LICENSE"}
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Intended Audience :: Education",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3 :: Only",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "accelerate>=0.25.0",
    "draccus==0.8.0",
    "einops",
    # "flash_attn==2.5.5",      # Here for documentation -- install *AFTER* editable install (follow README)
    "huggingface_hub",
    "json-numpy",
    "jsonlines",
    "matplotlib",
    "peft==0.11.1",
    "protobuf",
    "rich",
    "sentencepiece>=0.2.0",
    "timm>=0.9.10,<1.0.0",
    "tqdm",
    "requests",
    "Pillow",
    "wandb",
    "diffusers==0.30.3",
    "imageio",
    "uvicorn",
    "fastapi",
]

[project.optional-dependencies]
torch = [
    "torch",
    "torchvision",
    "torchaudio",
]
hf = [
    "transformers==4.40.1",
    "tokenizers==0.19.1",
]
hf_openvla_fork = [
    # IMPORTANT: Use this fork for bidirectional attn (for parallel decoding), if it builds on your platform.
    "transformers @ git+https://github.com/moojink/transformers-openvla-oft.git",
    "tokenizers==0.19.1",
]
rlds = [
    # RLDS dataloader + statistics rely on TensorFlow/TFDS; GPU is not required (CPU is fine).
    # Note: TensorFlow generally constrains NumPy to < 2.0.
    "numpy<2",
    "tensorflow>=2.16",
    "tensorflow_datasets>=4.9.3",
]
flash_attn = [
    # Optional training speedup; may be difficult/unavailable on some aarch64 setups.
    "packaging",
    "ninja",
    "flash-attn==2.5.5",
]
dev = [
    "black>=24.2.0",
    "gpustat",
    "ipython",
    "pre-commit",
    "ruff>=0.2.2",
]
sagemaker = [
    "boto3",
    "sagemaker"
]

[project.urls]
homepage = "https://github.com/moojink/openvla-oft"
repository = "https://github.com/moojink/openvla-oft"
documentation = "https://github.com/moojink/openvla-oft"

[tool.setuptools.packages.find]
where = ["."]
exclude = ["cache"]

[tool.setuptools.package-data]
"prismatic" = ["py.typed"]

[tool.black]
line-length = 121
target-version = ["py38", "py39", "py310"]
preview = true

[tool.ruff]
line-length = 121
target-version = "py38"

[tool.ruff.lint]
select = ["A", "B", "E", "F", "I", "RUF", "W"]
ignore = ["F722"]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["E402", "F401"]
